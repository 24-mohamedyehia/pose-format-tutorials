{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c91697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pose_format import Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3584dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_file_1 = '../data/pose_files/SGB_FSS_original.pose'\n",
    "save_path = \"../output/08_advanced_features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5cf0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pose(path: str) -> Pose:\n",
    "    with open(path, 'rb') as f:\n",
    "        return Pose.read(f.read())\n",
    "\n",
    "def save_as_pose(pose: Pose, output_path: str):\n",
    "    \"\"\"\n",
    "    Saves a Pose object to a .pose file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pose.write(f)\n",
    "    print(f\"‚úÖ Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31b3d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved to: ../output/08_advanced_features/loaded_pose.pose\n"
     ]
    }
   ],
   "source": [
    "pose = load_pose(pose_file_1)\n",
    "save_as_pose(pose, save_path + \"loaded_pose.pose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bac87",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Cropping and Component Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c9b52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_components(pose: Pose, components: list) -> Pose:\n",
    "    \"\"\"\n",
    "    Extract specific components\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    components : list\n",
    "        List of component names\n",
    "    \"\"\"\n",
    "    filtered = pose.get_components(components)\n",
    "    \n",
    "    print(f\"‚úÖ Extracted components: {components}\")\n",
    "    print(f\"   Original points count: {pose.body.data.shape[2]}\")\n",
    "    print(f\"   New points count: {filtered.body.data.shape[2]}\")\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8304137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted components: ['LEFT_HAND_LANDMARKS', 'RIGHT_HAND_LANDMARKS']\n",
      "   Original points count: 203\n",
      "   New points count: 42\n",
      "‚úÖ Saved to: ../output/08_advanced_features/hands_only.pose\n",
      "‚úÖ Extracted components: ['POSE_LANDMARKS', 'FACE_LANDMARKS']\n",
      "   Original points count: 203\n",
      "   New points count: 161\n",
      "‚úÖ Saved to: ../output/08_advanced_features/body_and_face.pose\n"
     ]
    }
   ],
   "source": [
    "# Example: Hands only\n",
    "hands_only = get_specific_components(pose, ['LEFT_HAND_LANDMARKS', 'RIGHT_HAND_LANDMARKS'])\n",
    "save_as_pose(hands_only, save_path + \"hands_only.pose\")\n",
    "# Example: Body and Face\n",
    "body_face = get_specific_components(pose, ['POSE_LANDMARKS', 'FACE_LANDMARKS'])\n",
    "save_as_pose(body_face, save_path + \"body_and_face.pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3767de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted specific points\n",
      "‚úÖ Saved to: ../output/08_advanced_features/upper_body.pose\n"
     ]
    }
   ],
   "source": [
    "def get_specific_points(pose: Pose, components: list, points_dict: dict) -> Pose:\n",
    "    \"\"\"\n",
    "    Extract specific points from specific components\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    components : list\n",
    "        List of component names\n",
    "    points_dict : dict\n",
    "        Dictionary: component name -> list of point names\n",
    "    \"\"\"\n",
    "    filtered = pose.get_components(components, points=points_dict)\n",
    "    \n",
    "    print(f\"‚úÖ Extracted specific points\")\n",
    "    return filtered\n",
    "\n",
    "# Example: Only specific points from the body\n",
    "upper_body = get_specific_points(\n",
    "    pose,\n",
    "    ['POSE_LANDMARKS'],\n",
    "    {\n",
    "        'POSE_LANDMARKS': [\n",
    "            'NOSE', 'LEFT_SHOULDER', 'RIGHT_SHOULDER',\n",
    "            'LEFT_ELBOW', 'RIGHT_ELBOW',\n",
    "            'LEFT_WRIST', 'RIGHT_WRIST',\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "save_as_pose(upper_body, save_path + \"upper_body.pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2687a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Removed components: ['POSE_WORLD_LANDMARKS']\n",
      "‚úÖ Saved to: ../output/08_advanced_features/pose_no_world.pose\n"
     ]
    }
   ],
   "source": [
    "def remove_components(pose: Pose, components_to_remove: list) -> Pose:\n",
    "    \"\"\"\n",
    "    Remove components from the pose\n",
    "    \"\"\"\n",
    "    filtered = pose.remove_components(components_to_remove)\n",
    "    \n",
    "    print(f\"‚úÖ Removed components: {components_to_remove}\")\n",
    "    return filtered\n",
    "\n",
    "# Example: Remove POSE_WORLD_LANDMARKS\n",
    "pose_no_world = remove_components(pose, ['POSE_WORLD_LANDMARKS'])\n",
    "save_as_pose(pose_no_world, save_path + \"pose_no_world.pose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183094f",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Computing Bounding Box\n",
    "\n",
    "üéØ **What is a Bounding Box?**\n",
    "\n",
    "A Bounding Box is the rectangle that surrounds a set of points.\n",
    "\n",
    "\n",
    "TOP_LEFT ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "            ‚îÇ             ‚îÇ\n",
    "            ‚îÇ   Points    ‚îÇ\n",
    "            ‚îÇ      ‚óè  ‚óè ‚óè ‚îÇ\n",
    "            ‚îÇ     ‚óè ‚óè  ‚óè  ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè BOTTOM_RIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27371859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bounding Box computed\n",
      "   Original shape: (133, 1, 203, 3)\n",
      "   BBox shape: (133, 1, 8, 3)\n",
      "‚úÖ Saved to: ../output/08_advanced_features/bbox.pose\n"
     ]
    }
   ],
   "source": [
    "def compute_bounding_box(pose: Pose) -> Pose:\n",
    "    \"\"\"\n",
    "    Compute bounding box for each component\n",
    "    \n",
    "    Returns two points for each component:\n",
    "    - TOP_LEFT: Upper left corner\n",
    "    - BOTTOM_RIGHT: Lower right corner\n",
    "    \"\"\"\n",
    "    bbox_pose = pose.bbox()\n",
    "    \n",
    "    print(\"‚úÖ Bounding Box computed\")\n",
    "    print(f\"   Original shape: {pose.body.data.shape}\")\n",
    "    print(f\"   BBox shape: {bbox_pose.body.data.shape}\")\n",
    "    \n",
    "    return bbox_pose\n",
    "\n",
    "bbox = compute_bounding_box(pose)\n",
    "\n",
    "save_as_pose(bbox, save_path + \"bbox.pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cc3195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hands_bounding_box(pose: Pose) -> dict:\n",
    "    \"\"\"\n",
    "    Get bounding box for hands only\n",
    "    \"\"\"\n",
    "    # Extract hands\n",
    "    hands = pose.get_components(['LEFT_HAND_LANDMARKS', 'RIGHT_HAND_LANDMARKS'])\n",
    "    \n",
    "    # Calculate bbox\n",
    "    bbox = hands.bbox()\n",
    "    \n",
    "    # Extract coordinates\n",
    "    data = bbox.body.data\n",
    "    \n",
    "    result = {}\n",
    "    for frame_idx in range(data.shape[0]):\n",
    "        # Left hand: points 0-1, Right hand: points 2-3\n",
    "        left_tl = data[frame_idx, 0, 0, :2]  # Top-Left\n",
    "        left_br = data[frame_idx, 0, 1, :2]  # Bottom-Right\n",
    "        right_tl = data[frame_idx, 0, 2, :2]\n",
    "        right_br = data[frame_idx, 0, 3, :2]\n",
    "        \n",
    "        result[frame_idx] = {\n",
    "            'left_hand': {'top_left': left_tl, 'bottom_right': left_br},\n",
    "            'right_hand': {'top_left': right_tl, 'bottom_right': right_br}\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "boxes = get_hands_bounding_box(pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91e033",
   "metadata": {},
   "source": [
    "### 2.1 Practical Uses:\n",
    "\n",
    "**Use Case 1: Track hand position**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d1b27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hand at: [284.1441650390625 400.3851013183594]\n",
      "Right hand at: [239.14031982421875 327.1969909667969]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "boxes = get_hands_bounding_box(pose)\n",
    "\n",
    "# Frame 10\n",
    "frame_10 = boxes[10]\n",
    "print(f\"Left hand at: {frame_10['left_hand']['top_left']}\")\n",
    "print(f\"Right hand at: {frame_10['right_hand']['top_left']}\")\n",
    "\n",
    "# Useful to know where hands are in each frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5685128",
   "metadata": {},
   "source": [
    "**Use Case 2: Detect hand crossing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a082a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: Hands are crossing!\n",
      "Frame 1: Hands are crossing!\n",
      "Frame 6: Hands are crossing!\n",
      "Frame 7: Hands are crossing!\n",
      "Frame 8: Hands are crossing!\n",
      "Frame 9: Hands are crossing!\n",
      "Frame 10: Hands are crossing!\n",
      "Frame 11: Hands are crossing!\n",
      "Frame 12: Hands are crossing!\n",
      "Frame 13: Hands are crossing!\n",
      "Frame 15: Hands are crossing!\n",
      "Frame 16: Hands are crossing!\n",
      "Frame 17: Hands are crossing!\n",
      "Frame 18: Hands are crossing!\n",
      "Frame 19: Hands are crossing!\n",
      "Frame 99: Hands are crossing!\n",
      "Frame 100: Hands are crossing!\n",
      "Frame 102: Hands are crossing!\n",
      "Frame 103: Hands are crossing!\n",
      "Frame 104: Hands are crossing!\n",
      "Frame 105: Hands are crossing!\n",
      "Frame 106: Hands are crossing!\n",
      "Frame 107: Hands are crossing!\n",
      "Frame 108: Hands are crossing!\n",
      "Frame 113: Hands are crossing!\n",
      "Frame 114: Hands are crossing!\n",
      "Frame 115: Hands are crossing!\n",
      "Frame 116: Hands are crossing!\n",
      "Frame 117: Hands are crossing!\n",
      "Frame 118: Hands are crossing!\n",
      "Frame 119: Hands are crossing!\n",
      "Frame 120: Hands are crossing!\n",
      "Frame 121: Hands are crossing!\n",
      "Frame 122: Hands are crossing!\n",
      "Frame 123: Hands are crossing!\n",
      "Frame 124: Hands are crossing!\n",
      "Frame 125: Hands are crossing!\n",
      "Frame 126: Hands are crossing!\n",
      "Frame 127: Hands are crossing!\n",
      "Frame 128: Hands are crossing!\n",
      "Frame 129: Hands are crossing!\n",
      "Frame 130: Hands are crossing!\n",
      "Frame 131: Hands are crossing!\n",
      "Frame 132: Hands are crossing!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def hands_are_crossing(bbox_frame):\n",
    "    \"\"\"Are the hands crossing?\"\"\"\n",
    "    left = bbox_frame['left_hand']\n",
    "    right = bbox_frame['right_hand']\n",
    "    \n",
    "    # Check for intersection\n",
    "    if (left['bottom_right'][0] > right['top_left'][0] and\n",
    "        left['top_left'][0] < right['bottom_right'][0]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Check all frames\n",
    "boxes = get_hands_bounding_box(pose)\n",
    "for frame_idx, bbox in boxes.items():\n",
    "    if hands_are_crossing(bbox):\n",
    "        print(f\"Frame {frame_idx}: Hands are crossing!\")\n",
    "        \n",
    "# Useful for signs like \"X\" or \"prayer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80a7f2",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Backend Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95f75f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Converted to PyTorch\n",
      "   Data type: <class 'pose_format.torch.masked.tensor.MaskedTensor'>\n"
     ]
    }
   ],
   "source": [
    "def convert_to_torch(pose: Pose):\n",
    "    \"\"\"\n",
    "    Convert to PyTorch tensors\n",
    "    \"\"\"\n",
    "    torch_pose = pose.torch()\n",
    "    \n",
    "    print(f\"‚úÖ Converted to PyTorch\")\n",
    "    print(f\"   Data type: {type(torch_pose.body.data)}\")\n",
    "    \n",
    "    return torch_pose\n",
    "\n",
    "torch_pose = convert_to_torch(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d139eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensorflow(pose: Pose):\n",
    "    \"\"\"\n",
    "    Convert to TensorFlow tensors\n",
    "    \"\"\"\n",
    "    tf_pose = pose.tensorflow()\n",
    "    \n",
    "    print(f\"‚úÖ Converted to TensorFlow\")\n",
    "    print(f\"   Data type: {type(tf_pose.body.data)}\")\n",
    "    \n",
    "    return tf_pose\n",
    "\n",
    "# tf_pose = convert_to_tensorflow(pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a1053",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Additional Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a52f4b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pose adjusted (focus)\n",
      "‚úÖ Saved to: ../output/08_advanced_features/focused.pose\n"
     ]
    }
   ],
   "source": [
    "def focus_pose(pose: Pose) -> Pose:\n",
    "    \"\"\"\n",
    "    Adjust pose to start from (0,0) and fill available space\n",
    "    Useful for display and visualization\n",
    "    \"\"\"\n",
    "    pose_copy = pose.copy()\n",
    "    pose_copy.focus()\n",
    "    \n",
    "    print(\"‚úÖ Pose adjusted (focus)\")\n",
    "    return pose_copy\n",
    "\n",
    "focused = focus_pose(pose)\n",
    "save_as_pose(focused, save_path + \"focused.pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dc196e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pose sliced\n",
      "   From frame 0 to 100 with step 1\n",
      "   Frames: 133 -> 100\n",
      "‚úÖ Saved to: ../output/08_advanced_features/first_100.pose\n",
      "‚úÖ Pose sliced\n",
      "   From frame 0 to 133 with step 2\n",
      "   Frames: 133 -> 67\n",
      "‚úÖ Saved to: ../output/08_advanced_features/every_second.pose\n"
     ]
    }
   ],
   "source": [
    "def slice_pose(pose: Pose, start: int = 0, end: int = None, step: int = 1) -> Pose:\n",
    "    \"\"\"\n",
    "    Slice a portion of the pose\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start : int\n",
    "        Start frame\n",
    "    end : int\n",
    "        End frame (None = last frame)\n",
    "    step : int\n",
    "        Step (1 = every frame, 2 = every 2nd frame, ...)\n",
    "    \"\"\"\n",
    "    pose_copy = pose.copy()\n",
    "    \n",
    "    if end is None:\n",
    "        end = pose_copy.body.data.shape[0]\n",
    "    \n",
    "    # Slice the body data directly\n",
    "    pose_copy.body.data = pose_copy.body.data[start:end:step]\n",
    "    \n",
    "    print(f\"‚úÖ Pose sliced\")\n",
    "    print(f\"   From frame {start} to {end} with step {step}\")\n",
    "    print(f\"   Frames: {pose.body.data.shape[0]} -> {pose_copy.body.data.shape[0]}\")\n",
    "    \n",
    "    return pose_copy\n",
    "\n",
    "# First 100 frames\n",
    "first_100 = slice_pose(pose, start=0, end=100)\n",
    "save_as_pose(first_100, save_path + \"first_100.pose\")\n",
    "\n",
    "# Every 2nd frame\n",
    "every_second = slice_pose(pose, step=2)\n",
    "save_as_pose(every_second, save_path + \"every_second.pose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec191fa",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Data Flattening\n",
    "\n",
    "**What is Flattening?**\n",
    "\n",
    "Flattening = Converting multi-dimensional data into 2D format (rows and columns)\n",
    "\n",
    "**Before Flattening:**\n",
    "```python\n",
    "# Data shape: [frames, people, points, dimensions]\n",
    "#            [100, 1, 75, 3]\n",
    "\n",
    "pose = load_pose('sign.pose')\n",
    "print(pose.body.data.shape)  # [100, 1, 75, 3]\n",
    "```\n",
    "\n",
    "**After Flattening:**\n",
    "```python\n",
    "# One row per point per frame\n",
    "flat = flatten_pose_data(pose)\n",
    "print(flat.shape)  # [N, 7]\n",
    "\n",
    "# Columns: [frame, person, point, confidence, x, y, z]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7fda769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data flattened\n",
      "   Shape: (26705, 7)\n",
      "   Columns: [frame, person, point, confidence, x, y, z]\n",
      "[[  0.           0.           0.           0.99545729 331.33071899\n",
      "  120.33316803  -0.83765996]\n",
      " [  0.           0.           1.           0.98735136 343.02304077\n",
      "  104.05989838  -0.78138584]\n",
      " [  0.           0.           2.           0.98721689 350.11105347\n",
      "  104.8104248   -0.78215271]\n",
      " [  0.           0.           3.           0.98832768 359.10119629\n",
      "  106.03274536  -0.78219563]\n",
      " [  0.           0.           4.           0.99146909 319.21643066\n",
      "  103.28619385  -0.78185833]]\n"
     ]
    }
   ],
   "source": [
    "def flatten_pose_data(pose: Pose) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flatten data for ML usage\n",
    "    Removes points with zero confidence\n",
    "    \"\"\"\n",
    "    flat = pose.body.flatten()\n",
    "    \n",
    "    print(f\"‚úÖ Data flattened\")\n",
    "    print(f\"   Shape: {flat.shape}\")\n",
    "    print(f\"   Columns: [frame, person, point, confidence, x, y, z]\")\n",
    "    \n",
    "    return flat\n",
    "\n",
    "flat_data = flatten_pose_data(pose)\n",
    "print(flat_data[:5]) # Display first 5 rows of flattened data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf99ca",
   "metadata": {},
   "source": [
    "### 5.1 Example - Export to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38f5598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data flattened\n",
      "   Shape: (26705, 7)\n",
      "   Columns: [frame, person, point, confidence, x, y, z]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the data\n",
    "flat = flatten_pose_data(pose)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(flat, columns=[\n",
    "    'frame', 'person', 'point', 'confidence', 'x', 'y', 'z'\n",
    "])\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(save_path + 'pose_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188dc98",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Features Summary\n",
    "\n",
    "| Feature | Function | Usage |\n",
    "|---------|----------|-------|\n",
    "| Cropping Components | `pose.get_components()` | Extract hands only, face, etc. |\n",
    "| Remove Components | `pose.remove_components()` | Delete unnecessary components |\n",
    "| Bounding Box | `pose.bbox()` | Calculate component bounds |\n",
    "| Focus Pose | `pose.focus()` | Center and scale pose |\n",
    "| Slice Pose | `pose.body.data[start:end:step]` | Extract frame range |\n",
    "| Flatten Data | `pose.body.flatten()` | Convert to 2D array for ML |\n",
    "| Backend Conversion | `pose.torch()` / `pose.tensorflow()` | Convert for training |\n",
    "\n",
    "### Key Operations Covered\n",
    "1. **Component Selection**: Extract or remove specific body parts\n",
    "2. **Bounding Box**: Calculate spatial boundaries for components\n",
    "3. **Data Transformation**: Flatten for ML, slice for frame selection\n",
    "4. **Backend Support**: Convert to PyTorch or TensorFlow formats\n",
    "\n",
    "### Best Practices\n",
    "- Use `get_components()` to reduce data dimensionality\n",
    "- Apply `bbox()` for spatial analysis and tracking\n",
    "- Choose appropriate backend for your deep learning framework"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose-format-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
